{"basics":{"name":"Tristan Torchet","label":"PhD Student in Electrical Engineering and Neuroscience","image":"prof_pic.jpg","email":"tristan.torchet@uzh.ch","phone":"+33 7 61 18 28 96","url":"https://tristantorchet.github.io/","summary":"PhD student working on hardware-software co-design, dendritic computing, and linear sequence models with a focus on brain-inspired computing.","location":{"address":"","postalCode":"","city":"Zürich","countryCode":"CH","region":"Switzerland"},"profiles":[{"network":"GitHub","username":"TristanTorchet","url":"https://github.com/TristanTorchet"},{"network":"LinkedIn","username":"tristantorchet","url":"https://www.linkedin.com/in/tristantorchet"},{"network":"Google Scholar","username":"Tristan Torchet","url":"https://scholar.google.com/citations?user=PIABIKoF5Y8C&hl=fr"}]},"work":[{"name":"Prediko","position":"Data Engineer Intern","url":"https://www.prediko.io","startDate":"2021-06-01","endDate":"2021-09-01","summary":"Implemented ML pipeline for time series forecasting and developed dashboard for company and user activity monitoring.","highlights":["Implemented pipeline for time series forecasts using ARIMA, ARIMAX, SARIMAX and ensemble techniques with Darts library","Developed full-stack dashboard (MongoDB, FastAPI, Docker, GCP) presented to investors for $5M funding round","Used machine learning algorithms and Gaussian Processes for stock management optimization"]}],"education":[{"institution":"Institute of Neuroinformatics, ETHZ and UZH","location":"Zürich, Switzerland","url":"https://www.ini.uzh.ch/en/research/groups/EIS.html","area":"Electrical Engineering and Neuroscience","studyType":"Joint Ph.D.","startDate":"2023-09-01","endDate":"Present","score":"","courses":["Hardware-software co-design","Dendritic computing","Linear sequence models"]},{"institution":"ETH Zürich","location":"Zürich, Switzerland","url":"https://ethz.ch/","area":"Electrical Engineering and Information Technology","studyType":"Master of Science","startDate":"2021-09-01","endDate":"2023-07-01","score":"5.36","courses":["Introduction to Machine Learning","Advanced Machine Learning","Neuromorphic Engineering I & II","VLSI I, II & III","Machine Learning on Microcontrollers","Introduction to Neuroinformatics","Deep Learning in Biological Networks"]},{"institution":"École Polytechnique Fédérale de Lausanne (EPFL)","location":"Lausanne, Switzerland","url":"https://www.epfl.ch/","area":"Electrical and Electronic Engineering","studyType":"Bachelor","startDate":"2017-09-01","endDate":"2021-07-01","score":"5.11","courses":["Analysis I, II, III, IV","Physics I, II, III, IV","Electrotechnics I & II","Electronics I & II"]}],"awards":[],"certificates":[],"publications":[{"name":"mGRADE: Minimal Recurrent Gating Meets Delay Convolutions for Lightweight Sequence Modeling","publisher":"Under Review","releaseDate":"2025","url":"https://arxiv.org/abs/2507.01829","summary":"Proposed a hybrid-memory architecture enabling efficient multi-scale temporal processing on edge devices with competitive results on long-range dependency tasks."},{"name":"Quantizing Small-Scale State-Space Models for Edge AI","publisher":"ACM International Conference on Neuromorphic Systems (ICONS)","releaseDate":"2025","url":"https://arxiv.org/abs/2506.12480","summary":"Demonstrated efficient low-bit state-space models through quantization-aware training with heterogeneous precision scheme reducing memory 6× without performance loss."},{"name":"DenRAM: neuromorphic dendritic architecture with RRAM for efficient temporal processing with delays","publisher":"Nature Communications","releaseDate":"2024","url":"https://doi.org/10.1038/s41467-024-47764-w","summary":"Developed hardware-aware training compatible with RRAM circuits for spiking neural networks achieving best performance for feedforward SNN models."}],"skills":[{"name":"Programming","level":"Advanced","icon":"fa-solid fa-code","keywords":["Python (JAX, PyTorch)","C","C++","CUDA"]},{"name":"Hardware Design","level":"Advanced","icon":"fa-solid fa-microchip","keywords":["SystemVerilog","Siemens QuestaSim®","Synopsys Design Compiler®","Cadence Innovus®","Cadence Virtuoso®"]}],"languages":[{"language":"French","fluency":"Native speaker","icon":""},{"language":"English","fluency":"C1","icon":""},{"language":"Italian","fluency":"C1","icon":""},{"language":"Spanish","fluency":"B2","icon":""}],"interests":[{"name":"Research","icon":"fa-solid fa-brain","keywords":["Brain-inspired Computing","Hardware-software Co-design","Sequence Modeling","Edge AI"]}],"references":[{"name":"Prof. Melika Payvand","reference":"Main supervisor, Emerging Intelligent Substrates Lab, Institute of Neuroinformatics, ETHZ/UZH","email":"melika@ini.uzh.ch"},{"name":"Prof. Shih-Chii Liu","reference":"Committee member, Institute of Neuroinformatics, ETHZ/UZH","email":"shih@ini.uzh.ch"},{"name":"Dr. Abu Sebastian","reference":"Committee member, IBM Research","email":"ase@zurich.ibm.com"},{"name":"Prof. Luca Benini","reference":"Committee member, ETHZ","email":"lbenini@iis.ee.ethz.ch"}],"projects":[{"name":"Hybrid recurrent-attention LLM","summary":"Pretrained a 370M-parameter HGRN-based model on 200B tokens FineWeb-Edu using 8xH100 cluster, comparing pure recurrent to hybrid HGRN-attention architectures.","highlights":["Multi-GPU LLM training","Loihi-2 deployment","Quantization optimization"],"url":""},{"name":"LOKUM: SRAM Analog In-Memory-Computing Test Chip","summary":"Set up development pipeline for Global Foundries 22nm FD-SOI and developed digital controller for analog macro and I/O communication.","highlights":["GF 22nm FD-SOI","Siemens QuestaSim®","Cadence Innovus®"],"url":""},{"name":"Event-driven Dynamic Sparse Training for SNNs","summary":"Proposed EDST algorithm for spiking neural networks maintaining constant high sparsity during training, outperforming traditional pruning techniques.","highlights":["Hardware-aware simulations","Custom ASIC circuit","Mixed-signal simulations"],"url":"https://doi.org/10.1109/ASYNC58294.2023.10239574"}]}